#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ feedparser è·å– NodeSeek RSS å†…å®¹çš„è„šæœ¬
ç­›é€‰æŒ‡å®šç±»åˆ«ä¸”æ ‡é¢˜åŒ…å«ç‰¹å®šå…³é”®è¯çš„é¡¹ç›®å¹¶æ¨é€åˆ°Telegram
æ”¯æŒç¯å¢ƒå˜é‡é…ç½®
"""

import requests
import time
import random
import feedparser
from email.utils import parsedate_to_datetime
from datetime import datetime
import asyncio
from telegram import Bot
import json
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
TG_BOT_TOKEN = os.getenv('TG_BOT_TOKEN')
TG_CHAT_ID = os.getenv('TG_CHAT_ID')
CATEGORIES = os.getenv('CATEGORIES', '').strip()
KEYWORDS = os.getenv('KEYWORDS', '').strip()
WAIT_TIME = int(os.getenv('WAIT_TIME', '5'))
CLEANUP_DAYS = int(os.getenv('CLEANUP_DAYS', '7'))

# éªŒè¯å¿…å¡«ç¯å¢ƒå˜é‡
if not TG_BOT_TOKEN:
    raise ValueError("TG_BOT_TOKEN ç¯å¢ƒå˜é‡ä¸èƒ½ä¸ºç©º")
if not TG_CHAT_ID:
    raise ValueError("TG_CHAT_ID ç¯å¢ƒå˜é‡ä¸èƒ½ä¸ºç©º")

# è§£æç¯å¢ƒå˜é‡åˆ—è¡¨çš„å‡½æ•°
def parse_list_env(env_value):
    """è§£æç¯å¢ƒå˜é‡åˆ—è¡¨ï¼Œæ”¯æŒJSONæ•°ç»„æ ¼å¼å’Œé€—å·åˆ†éš”æ ¼å¼"""
    if not env_value:
        return []
    
    # å°è¯•è§£æä¸ºJSONæ•°ç»„
    try:
        parsed = json.loads(env_value)
        if isinstance(parsed, list):
            return [str(item).strip() for item in parsed if str(item).strip()]
    except (json.JSONDecodeError, TypeError):
        pass
    
    # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œåˆ™æŒ‰é€—å·åˆ†éš”è§£æ
    return [item.strip() for item in env_value.split(',') if item.strip()]

# è§£æå¤šä¸ª CHAT_IDï¼ˆæ”¯æŒJSONæ•°ç»„æ ¼å¼å’Œé€—å·åˆ†éš”ï¼‰
CHAT_IDS = parse_list_env(TG_CHAT_ID)

# è§£æå¤šä¸ª CATEGORIESï¼ˆæ”¯æŒJSONæ•°ç»„æ ¼å¼å’Œé€—å·åˆ†éš”ï¼‰
CATEGORY_LIST = parse_list_env(CATEGORIES)
KEYWORD_LIST = parse_list_env(KEYWORDS)

# æ”¯æŒçš„ç±»åˆ«åŠå…¶å¯¹åº”çš„æ¶ˆæ¯æ ‡é¢˜
CATEGORY_TITLES = {
    'daily': 'ğŸ”” <b>NodeSeekæ—¥å¸¸å¸–å­</b>',
    'tech': 'ğŸ”” <b>NodeSeekæŠ€æœ¯å¸–å­</b>',
    'info': 'ğŸ”” <b>NodeSeekæƒ…æŠ¥å¸–å­</b>',
    'review': 'ğŸ”” <b>NodeSeekæµ‹è¯„å¸–å­</b>',
    'trade': 'ğŸ”” <b>NodeSeekäº¤æ˜“å¸–å­</b>',
    'carpool': 'ğŸ”” <b>NodeSeekæ‹¼è½¦å¸–å­</b>',
    'dev': 'ğŸ”” <b>NodeSeek devå¸–å­</b>',
    'photo-share': 'ğŸ”” <b>NodeSeekè´´å›¾å¸–å­</b>',
    'expose': 'ğŸ”” <b>NodeSeekæ›å…‰å¸–å­</b>',
    'promotion': 'ğŸ”” <b>NodeSeekå•†å®¶ä¿¡æ¯</b>'
}

# å­˜å‚¨ä¸Šæ¬¡å‘é€çš„å†…å®¹ï¼Œé¿å…é‡å¤å‘é€
# åœ¨ Docker ç¯å¢ƒä¸­ä½¿ç”¨ /app/data ç›®å½•ï¼Œæœ¬åœ°ç¯å¢ƒä½¿ç”¨å½“å‰ç›®å½•
LAST_SENT_FILE = "/app/data/last_sent.json" if os.path.exists("/app/data") else "last_sent.json"

def load_last_sent():
    """åŠ è½½ä¸Šæ¬¡å‘é€çš„å†…å®¹"""
    try:
        if os.path.exists(LAST_SENT_FILE):
            with open(LAST_SENT_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except:
        pass
    return {}

def save_last_sent(data):
    """ä¿å­˜æœ¬æ¬¡å‘é€çš„å†…å®¹ï¼Œå¹¶æ¸…ç†è¿‡æœŸè®°å½•"""
    try:
        # æ¸…ç†è¿‡æœŸè®°å½•ï¼ˆä¿ç•™æœ€è¿‘Nå¤©çš„è®°å½•ï¼‰
        cleaned_data = cleanup_old_records(data, CLEANUP_DAYS)
        
        with open(LAST_SENT_FILE, 'w', encoding='utf-8') as f:
            json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
        
        # æ‰“å°æ¸…ç†ç»Ÿè®¡
        removed_count = len(data) - len(cleaned_data)
        if removed_count > 0:
            print(f"  ğŸ§¹ æ¸…ç†äº† {removed_count} æ¡è¿‡æœŸè®°å½•ï¼Œå½“å‰ä¿ç•™ {len(cleaned_data)} æ¡è®°å½•")
            
    except Exception as e:
        print(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

def cleanup_old_records(data, days_to_keep=7):
    """æ¸…ç†è¿‡æœŸè®°å½•ï¼Œåªä¿ç•™æŒ‡å®šå¤©æ•°å†…çš„è®°å½•"""
    from datetime import timedelta
    
    if not data:
        return data
    
    # è®¡ç®—è¿‡æœŸæ—¶é—´ï¼ˆ7å¤©å‰ï¼‰
    cutoff_time = datetime.now() - timedelta(days=days_to_keep)
    
    cleaned_data = {}
    
    for item_id, item_info in data.items():
        try:
            # è·å–å‘é€æ—¶é—´
            sent_time_str = item_info.get('sent_time')
            if not sent_time_str:
                # å¦‚æœæ²¡æœ‰sent_timeï¼Œä¿ç•™è¿™æ¡è®°å½•ï¼ˆå‘åå…¼å®¹ï¼‰
                cleaned_data[item_id] = item_info
                continue
            
            # è§£æå‘é€æ—¶é—´
            sent_time = datetime.fromisoformat(sent_time_str)
            
            # å¦‚æœè®°å½•åœ¨ä¿ç•™æœŸå†…ï¼Œåˆ™ä¿ç•™
            if sent_time >= cutoff_time:
                cleaned_data[item_id] = item_info
                
        except (ValueError, TypeError) as e:
            # å¦‚æœæ—¶é—´è§£æå¤±è´¥ï¼Œä¿ç•™è¿™æ¡è®°å½•ï¼ˆå‘åå…¼å®¹ï¼‰
            print(f"  âš ï¸ è§£æè®°å½•æ—¶é—´å¤±è´¥ï¼Œä¿ç•™è®°å½•: {item_id}")
            cleaned_data[item_id] = item_info
    
    return cleaned_data

async def send_to_telegram(message, chat_id):
    """å‘é€æ¶ˆæ¯åˆ°æŒ‡å®šçš„TelegramèŠå¤©"""
    try:
        bot = Bot(token=TG_BOT_TOKEN)
        await bot.send_message(
            chat_id=chat_id,
            text=message,
            parse_mode='HTML',
            disable_web_page_preview=False
        )
        print(f"  âœ“ æ¶ˆæ¯å·²å‘é€åˆ°Telegram (Chat ID: {chat_id})")
        return True
    except Exception as e:
        print(f"  âœ— å‘é€Telegramæ¶ˆæ¯å¤±è´¥ (Chat ID: {chat_id}): {e}")
        return False

async def send_to_all_chats(message):
    """å‘é€æ¶ˆæ¯åˆ°æ‰€æœ‰é…ç½®çš„èŠå¤©"""
    success_count = 0
    for chat_id in CHAT_IDS:
        if await send_to_telegram(message, chat_id):
            success_count += 1
        # æ·»åŠ å‘é€é—´éš”ï¼Œé¿å…é¢‘ç‡é™åˆ¶
        if len(CHAT_IDS) > 1:
            await asyncio.sleep(0.5)
    
    print(f"  âœ“ æ¶ˆæ¯å‘é€å®Œæˆ: {success_count}/{len(CHAT_IDS)} ä¸ªèŠå¤©")
    return success_count > 0

def escape_html(text):
    """è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦"""
    # HTMLéœ€è¦è½¬ä¹‰çš„ç‰¹æ®Šå­—ç¬¦
    text = text.replace('&', '&amp;')
    text = text.replace('<', '&lt;')
    text = text.replace('>', '&gt;')
    return text

def format_time(time_str):
    """æ ¼å¼åŒ–æ—¶é—´ä¸ºç®€æ´æ ¼å¼ï¼Œè½¬æ¢ä¸ºGMT+8"""
    try:
        from datetime import timezone, timedelta
        
        # è·³è¿‡æ— æ•ˆæ—¶é—´
        if time_str in ["N/A", "", None]:
            return "N/A"
        
        dt = None
        
        # é¦–å…ˆå°è¯•è§£æRFC 2822æ ¼å¼ (å¦‚: "Fri, 11 Jul 2025 10:33:33 GMT")
        try:
            dt = parsedate_to_datetime(time_str)
            # parsedate_to_datetimeå·²ç»å¤„ç†äº†æ—¶åŒºä¿¡æ¯
        except Exception:
            # å¦‚æœRFC 2822æ ¼å¼è§£æå¤±è´¥ï¼Œå°è¯•ISOæ ¼å¼
            try:
                if 'T' in time_str:  # ISOæ ¼å¼
                    if time_str.endswith('Z'):
                        # UTCæ—¶é—´
                        dt = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                    elif '+' in time_str or '-' in time_str[-6:]:
                        # å¸¦æ—¶åŒºçš„æ—¶é—´
                        dt = datetime.fromisoformat(time_str)
                    else:
                        # æ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾ä¸ºUTC
                        dt = datetime.fromisoformat(time_str)
                        dt = dt.replace(tzinfo=timezone.utc)
            except Exception:
                # éƒ½è§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
                return time_str
        
        # å¦‚æœæˆåŠŸè§£ææ—¶é—´ï¼Œè½¬æ¢ä¸ºGMT+8
        if dt:
            gmt8 = timezone(timedelta(hours=8))
            dt_gmt8 = dt.astimezone(gmt8)
            
            # æ ¼å¼åŒ–ä¸º å¹´-æœˆ-æ—¥ æ—¶:åˆ†
            return dt_gmt8.strftime("%Y-%m-%d %H:%M")
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
        return time_str
        
    except Exception as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
        print(f"  âš ï¸ æ—¶é—´è§£æå¤±è´¥: {time_str} - {e}")
        return time_str

def format_message(item):
    """æ ¼å¼åŒ–æ¶ˆæ¯å†…å®¹ - æ ¹æ®categoryä½¿ç”¨ä¸åŒçš„æ ‡é¢˜"""
    # è·å–categoryå¯¹åº”çš„æ ‡é¢˜
    category = item.get('category', '').lower()
    title = CATEGORY_TITLES.get(category, 'ğŸ”” <b>NodeSeekå¸–å­</b>')
    
    # æ ¼å¼åŒ–æ—¶é—´
    formatted_time = format_time(item['pub_date'])
    
    # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
    escaped_title = escape_html(item['title'])
    escaped_time = escape_html(formatted_time)
    escaped_link = escape_html(item['link'])
    
    creator = item.get('creator', 'N/A')
    escaped_creator = escape_html(creator)
    
    message = f"""{title}

<b>ã€è´¦å·ã€‘ </b>{escaped_creator}
<b>ã€ä¸»é¢˜ã€‘ <a href="{escaped_link}">{escaped_title}</a></b>"""
    
    return message

def get_nodeseek_rss(url):
    """
    ä½¿ç”¨ feedparser è·å– NodeSeek RSS å†…å®¹
    æ¯æ¬¡è°ƒç”¨éƒ½ä¼šåˆ›å»ºæ–°çš„ requests ä¼šè¯
    """
    session = None
    try:
        # æ¯æ¬¡éƒ½åˆ›å»ºæ–°çš„ session
        session = requests.Session()
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'
        }
        session.headers.update(headers)
        
        # æ·»åŠ éšæœºå»¶è¿Ÿ
        time.sleep(random.uniform(1, 3))
        
        print(f"  æ­£åœ¨ä½¿ç”¨ feedparser è·å– NodeSeek RSS å†…å®¹: {url}")
        
        # å‘é€è¯·æ±‚
        response = session.get(url, timeout=10)
        
        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code == 200:
            print(f"  âœ“ æˆåŠŸè·å–å†…å®¹ (çŠ¶æ€ç : {response.status_code})")
            
            # ä½¿ç”¨ feedparser è§£æ RSS
            feed = feedparser.parse(response.text)
            
            if not feed.entries:
                print("  âœ— Feed é‡Œæš‚æ—¶æ²¡æœ‰æ¡ç›®")
                return None
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            items = []
            for entry in feed.entries:
                # è·å–å‘å¸ƒæ—¶é—´
                published = "N/A"
                if hasattr(entry, "published"):
                    published = entry.published
                elif hasattr(entry, "updated"):
                    published = entry.updated
                
                # ä¿æŒåŸå§‹æ—¶é—´æ ¼å¼ï¼Œè®©format_timeå‡½æ•°å¤„ç†è½¬æ¢
                
                # è·å–æè¿°
                description = "N/A"
                if hasattr(entry, "summary"):
                    description = entry.summary
                elif hasattr(entry, "description"):
                    description = entry.description
                
                # è·å–ä½œè€…ä¿¡æ¯ (NodeSeek ä½¿ç”¨ dc:creator)
                creator = "N/A"
                if hasattr(entry, "authors") and entry.authors:
                    creator = entry.authors[0].get('name', 'N/A')
                elif hasattr(entry, "author"):
                    creator = entry.author
                elif hasattr(entry, "dc_creator"):
                    creator = entry.dc_creator
                # å°è¯•ä»tagsä¸­è·å–dc:creator
                if creator == "N/A" and hasattr(entry, "tags"):
                    for tag in entry.tags:
                        if tag.get('term') and 'creator' in tag.get('label', '').lower():
                            creator = tag.get('term')
                            break
                
                # è·å–åˆ†ç±»ä¿¡æ¯
                category = "N/A"
                if hasattr(entry, "category"):
                    category = entry.category
                elif hasattr(entry, "tags") and entry.tags:
                    # æŸ¥æ‰¾categoryæ ‡ç­¾
                    for tag in entry.tags:
                        if tag.get('term'):
                            category = tag.get('term')
                            break
                
                rss_item = {
                    'title': entry.title if hasattr(entry, 'title') else 'N/A',
                    'link': entry.link if hasattr(entry, 'link') else 'N/A',
                    'description': description,
                    'pub_date': published,
                    'creator': creator,
                    'category': category
                }
                items.append(rss_item)
            
            return items
            
        else:
            print(f"  âœ— è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None
            
    except Exception as e:
        print(f"  âœ— feedparser è¯·æ±‚å¼‚å¸¸: {e}")
        return None
    finally:
        # ç¡®ä¿ session è¢«å…³é—­
        if session:
            try:
                session.close()
                print(f"  âœ“ requests ä¼šè¯å·²å…³é—­")
            except:
                pass

def print_rss_item(item):
    """
    æ‰“å° RSS é¡¹ç›®ä¿¡æ¯ - ç®€çº¦é£æ ¼
    """
    # æ ¼å¼åŒ–æ—¶é—´
    formatted_time = format_time(item['pub_date'])
    
    print(f"\n{'-'*60}")
    print(f"ã€NodeSeekã€‘æœ€æ–°é¡¹ç›®")
    print(f"{'-'*60}")
    print(f"æ ‡é¢˜: {item['title']}")
    print(f"åˆ†ç±»: {item.get('category', 'N/A')}")
    print(f"ä½œè€…: {item.get('creator', 'N/A')}")
    print(f"æ—¶é—´: {formatted_time}")
    print(f"é“¾æ¥: {item['link']}")
    print(f"{'-'*60}")

async def process_rss_feed(rss_url, last_sent):
    """
    å¤„ç†NodeSeek RSSæº
    """
    print(f"\n{'='*80}")
    print(f"æ­£åœ¨å¤„ç† NodeSeek")
    print(f"ç›®æ ‡ URL: {rss_url}")
    print("-" * 80)
    
    # è·å–RSSå†…å®¹
    items = get_nodeseek_rss(rss_url)
    
    if items is None:
        print(f"âœ— æ— æ³•è·å– NodeSeek RSS å†…å®¹")
        return False, None
        
    if not items:
        print(f"âœ— NodeSeek æ²¡æœ‰æ‰¾åˆ° RSS é¡¹ç›®")
        return False, None
    
    print(f"âœ“ æˆåŠŸè§£æ NodeSeek RSSï¼Œå…±æ‰¾åˆ° {len(items)} ä¸ªé¡¹ç›®")
    
    # ç¬¬ä¸€æ­¥ï¼šç­›é€‰æŒ‡å®šç±»åˆ«çš„é¡¹ç›®
    category_filtered = []
    if CATEGORY_LIST:
        for item in items:
            if item.get('category', '').lower() in [cat.lower() for cat in CATEGORY_LIST]:
                category_filtered.append(item)
        print(f"  âœ“ ç­›é€‰æŒ‡å®šç±»åˆ« {CATEGORY_LIST}ï¼Œä» {len(items)} ä¸ªé¡¹ç›®ä¸­ç­›é€‰å‡º {len(category_filtered)} ä¸ª")
    else:
        category_filtered = items
        print(f"  âœ“ æœªæŒ‡å®šç±»åˆ«ç­›é€‰ï¼Œå¤„ç†æ‰€æœ‰ {len(items)} ä¸ªé¡¹ç›®")
    
    if not category_filtered:
        print(f"  â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°æŒ‡å®šç±»åˆ«çš„é¡¹ç›®")
        return True, None
    
    # ç¬¬äºŒæ­¥ï¼šå¦‚æœæœ‰å…³é”®è¯ï¼Œç­›é€‰æ ‡é¢˜åŒ…å«æŒ‡å®šå…³é”®è¯çš„é¡¹ç›®
    if KEYWORD_LIST:
        filtered_items = []
        for item in category_filtered:
            title = item.get('title', '').lower()  # è½¬ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
            
            # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«ä»»æ„ä¸€ä¸ªå…³é”®è¯
            found_keyword = None
            for keyword in KEYWORD_LIST:
                if keyword.lower() in title:  # å…³é”®è¯ä¹Ÿè½¬å°å†™åŒ¹é…
                    found_keyword = keyword
                    break
            
            if found_keyword:
                item['matched_keyword'] = found_keyword  # è®°å½•åŒ¹é…çš„å…³é”®è¯
                filtered_items.append(item)
        
        if not filtered_items:
            print(f"  â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ…å«æŒ‡å®šå…³é”®è¯çš„é¡¹ç›®")
            print(f"  ğŸ“ å…³é”®è¯åˆ—è¡¨: {', '.join(KEYWORD_LIST)}")
            return True, None
        
        print(f"  âœ“ å…³é”®è¯ç­›é€‰ï¼Œä» {len(category_filtered)} ä¸ªé¡¹ç›®ä¸­ç­›é€‰å‡º {len(filtered_items)} ä¸ª")
        print(f"  ğŸ“ å…³é”®è¯åˆ—è¡¨: {', '.join(KEYWORD_LIST)}")
    else:
        filtered_items = category_filtered
        print(f"  âœ“ æœªæŒ‡å®šå…³é”®è¯ç­›é€‰ï¼Œå¤„ç†æ‰€æœ‰ {len(category_filtered)} ä¸ªé¡¹ç›®")
    
    # å¤„ç†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®
    latest_items = filtered_items
    print(f"  âœ“ å‡†å¤‡å¤„ç†æ‰€æœ‰ {len(latest_items)} ä¸ªç¬¦åˆæ¡ä»¶çš„é¡¹ç›®")
    
    new_items = []
    all_updates = {}
    
    # æ£€æŸ¥æ¯ä¸ªé¡¹ç›®æ˜¯å¦ä¸ºæ–°å†…å®¹
    for item in latest_items:
        # ä½¿ç”¨ä½œè€…+å‘å¸ƒæ—¶é—´ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
        creator = item.get('creator', 'N/A')
        pub_date = item.get('pub_date', 'N/A')
        item_id = f"NodeSeek_{creator}_{pub_date}"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„ä½œè€…+æ—¶é—´ç»„åˆ
        if item_id not in last_sent:
            # è¿™æ˜¯æ–°å†…å®¹
            new_items.append(item)
            all_updates[item_id] = {
                'creator': creator,
                'pub_date': pub_date,
                'title': item.get('title', ''),
                'category': item.get('category', ''),
                'sent_time': datetime.now().isoformat()
            }
            matched_keyword = item.get('matched_keyword', 'æ— å…³é”®è¯åŒ¹é…')
            print(f"  ğŸ†• å‘ç°æ–°å†…å®¹ [ç±»åˆ«: {item.get('category', 'N/A')}] [å…³é”®è¯: {matched_keyword}]: {item.get('title', '')[:50]}...")
        else:
            print(f"  â„¹ï¸ å·²å­˜åœ¨å†…å®¹: {item.get('title', '')[:50]}...")
    
    if not new_items:
        print(f"  â„¹ï¸ æ²¡æœ‰å‘ç°æ–°å†…å®¹ï¼Œè·³è¿‡å‘é€")
        return True, None
    
    print(f"  âœ“ å‘ç° {len(new_items)} ä¸ªæ–°å†…å®¹ï¼Œå‡†å¤‡å‘é€åˆ°Telegram")
    
    # å‘é€æ‰€æœ‰æ–°å†…å®¹åˆ°Telegram
    success_count = 0
    for i, item in enumerate(new_items, 1):
        print(f"  ğŸ“¤ æ­£åœ¨å‘é€ç¬¬ {i}/{len(new_items)} ä¸ªæ–°å†…å®¹...")
        
        # æ‰“å°é¡¹ç›®ä¿¡æ¯
        print_rss_item(item)
        
        # æ ¼å¼åŒ–æ¶ˆæ¯
        message = format_message(item)
        
        # å‘é€åˆ°æ‰€æœ‰èŠå¤©
        if await send_to_all_chats(message):
            success_count += 1
            # æ·»åŠ å‘é€é—´éš”ï¼Œé¿å…é¢‘ç‡é™åˆ¶
            if i < len(new_items):  # ä¸æ˜¯æœ€åä¸€ä¸ª
                await asyncio.sleep(1)  # ç­‰å¾…1ç§’
        else:
            print(f"  âœ— ç¬¬ {i} ä¸ªå†…å®¹å‘é€å¤±è´¥")
    
    print(f"  âœ… æˆåŠŸå‘é€ {success_count}/{len(new_items)} ä¸ªæ–°å†…å®¹")
    
    if success_count > 0:
        return True, all_updates
    else:
        return False, None

async def fetch_rss_once():
    """
    æ‰§è¡Œä¸€æ¬¡RSSè·å–æ“ä½œ
    """
    rss_url = 'https://rss.nodeseek.com/'
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"\n{'='*80}")
    print(f"å¼€å§‹æ–°ä¸€è½®RSSè·å– - {current_time}")
    print(f"å°†è·å– NodeSeek RSS æœ€æ–°é¡¹ç›®")
    print("é…ç½®ä¿¡æ¯ï¼š")
    print(f"  - ç±»åˆ«ç­›é€‰: {CATEGORY_LIST if CATEGORY_LIST else 'å…¨éƒ¨'}")
    print(f"  - å…³é”®è¯ç­›é€‰: {KEYWORD_LIST if KEYWORD_LIST else 'æ— '}")
    print(f"  - å‘é€ç›®æ ‡: {len(CHAT_IDS)} ä¸ªèŠå¤©")
    print(f"  - ç­‰å¾…æ—¶é—´: {WAIT_TIME} ç§’")
    print("=" * 80)
    
    # åŠ è½½ä¸Šæ¬¡å‘é€çš„è®°å½•
    last_sent = load_last_sent()
    
    # å¤„ç†RSSæº
    success, updates = await process_rss_feed(rss_url, last_sent)
    
    # ä¿å­˜æ›´æ–°çš„è®°å½•
    if updates:
        last_sent.update(updates)
        save_last_sent(last_sent)
        print(f"  ğŸ’¾ å·²ä¿å­˜ {len(updates)} æ¡æ–°è®°å½•")
    
    print(f"\n{'='*80}")
    print(f"æœ¬è½®å¤„ç†å®Œæˆï¼{'æˆåŠŸ' if success else 'å¤±è´¥'} - {current_time}")
    print("=" * 80)
    
    return success

async def main():
    """
    ä¸»å‡½æ•° - å¾ªç¯è·å–RSSæºå¹¶å‘é€åˆ°Telegram
    """
    print("NodeSeek RSS å¾ªç¯è·å–å·¥å…· + Telegramæ¨é€")
    print(f"æ¯{WAIT_TIME}ç§’è‡ªåŠ¨è·å–æœ€æ–°RSSé¡¹ç›®")
    print("é…ç½®ä¿¡æ¯ï¼š")
    print(f"  - ç±»åˆ«ç­›é€‰: {CATEGORY_LIST if CATEGORY_LIST else 'å…¨éƒ¨'}")
    print(f"  - å…³é”®è¯ç­›é€‰: {KEYWORD_LIST if KEYWORD_LIST else 'æ— '}")
    print(f"  - å‘é€ç›®æ ‡: {len(CHAT_IDS)} ä¸ªèŠå¤©")
    print("ç¬¦åˆæ¡ä»¶çš„æ–°å†…å®¹å°†è‡ªåŠ¨æ¨é€åˆ°Telegram")
    print("æŒ‰ Ctrl+C é€€å‡ºç¨‹åº")
    print("=" * 80)
    
    # æ¸…ç©ºå†å²è®°å½•ï¼Œç¡®ä¿é‡æ–°å¯åŠ¨æ—¶å‘é€å½“å‰æœ€æ–°å†…å®¹
    if os.path.exists(LAST_SENT_FILE):
        os.remove(LAST_SENT_FILE)
        print("ğŸ—‘ï¸ å·²æ¸…ç©ºå†å²è®°å½•ï¼Œé‡æ–°å¼€å§‹ç›‘æ§")
        print("=" * 80)
    
    try:
        while True:
            # æ‰§è¡Œä¸€æ¬¡RSSè·å–
            await fetch_rss_once()
            
            # ç­‰å¾…æŒ‡å®šæ—¶é—´ï¼Œæ˜¾ç¤ºå€’è®¡æ—¶
            print(f"\nç­‰å¾…{WAIT_TIME}ç§’åè¿›è¡Œä¸‹ä¸€è½®è·å–...")
            for i in range(WAIT_TIME, 0, -1):
                print(f"å€’è®¡æ—¶: {i}ç§’", end="\r")
                await asyncio.sleep(1)
            print(" " * 20, end="\r")  # æ¸…é™¤å€’è®¡æ—¶æ˜¾ç¤º
            
    except KeyboardInterrupt:
        print(f"\n\n{'='*80}")
        print("ç”¨æˆ·ä¸­æ–­ç¨‹åºï¼Œæ­£åœ¨é€€å‡º...")
        print("æ„Ÿè°¢ä½¿ç”¨RSSè·å–å·¥å…·ï¼")
        print("=" * 80)
    except Exception as e:
        print(f"\nç¨‹åºå‘ç”Ÿå¼‚å¸¸: {e}")
        print("ç¨‹åºå°†é€€å‡º")

def run_main():
    """è¿è¡Œä¸»ç¨‹åº"""
    asyncio.run(main())

if __name__ == "__main__":
    run_main()